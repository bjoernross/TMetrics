\subsection{Umsetzung und Problemstellungen}
\label{sec:restUmsetzungen}
\subsubsection{Transactor}
Wie bereits oben beschrieben wird im \texttt{Transactor} die Verbindung zur Datenbank erstellt und die einzelnen Abfragen abgeschickt. Hierzu wird im Konstruktor der Klasse eine Verbindung zur Datenbank hergestellt. Die benötigten Parameter für die Verbindung werden aus einer \texttt{properties}-Datei geladen. Für jede Anfrage, die an den REST-Service gesendet wird, gibt es in dieser Klasse eine eigene Methode, die die SQL-Anfrage erstellt und abschickt. 

Die Anfragen werden mit Hilfe von \texttt{PreparedStatements} erstellt. Ein Anfragestring wird hierbei an den Konstruktor des \texttt{PreparedStatements} übergeben und die einzelnen Parameter mit einem Fragezeichen markiert. Die Werte für diese Parameter können dann im nächsten Schritt anhand eines Indexes gesetzt werden. Bei Anfragen, die optionale Parameter enthalten, müssen diese Anfragestrings dynamisch angepasst werden. Ein Problem, das dabei auftrat, sind die unterschiedlichen Indizes, die der gleiche Parameter bei unterschiedlichen Anzahlen von Anfrageparametern annehmen kann. Ein erster Ansatz dies zu lösen bestand darin, alle verschiedenen Kombinationen von gesetzten und nicht gesetzten Parametern durchzugehen und die Parameter für das \texttt{PreparedStatement} explizit zu setzen. Dies ist jedoch bereits ab einer kleinen Anzahl von Parametern nicht mehr praktikabel. Als sehr gute Lösung erwies es sich eine Laufvariable einzuführen, die nach jedem gesetzten Parameter um eins erhöht wird. So musste im Gegensatz zu allen Kombinationen von gesetzten und nicht gesetzten Parametern nur jeder einzelne Parameter überprüft werden. Sobald das \texttt{PreparedStatement} fertig gestellt ist, kann es an die Datenbank geschickt werden. 

Das Ergebnis der Anfrage liegt dann zuerst in einem \texttt{ResultSet} des \texttt{java.sql}-Packages vor. Diese \texttt{ResultSet}s werden dann direkt in die entsprechenden \textit{Data Transfer Objects} umgewandelt. Bei komplexeren DTOs wurden für diese Aufgabe Builder-Klassen implementiert, die das Befüllen der Objekte komfortabler machen.

In einer ersten Version des \texttt{Transactor}s wurden all diese Operationen in einem \texttt{try\-catch}-Block ausgeführt, um Exceptions, die bei dem Verbindungsaufbau mit der Datenbank oder beim Ausführen der Anfragen geworfen werden können, abzufangen. In dieser Version wurden die Fehlermeldungen direkt in den \texttt{Envelope} geschrieben und dieser zurückgegeben. Da diese Art der Fehlerbehandlung zu Problemen führte, wie im Unterkapitel zu den Service-Klassen näher beschrieben ist, werden die Exceptions in der aktuellen Version direkt weitergeworfen. Die \texttt{try-catch}-Struktur wurde in der \texttt{Transactor}-Klasse allerdings beibehalten, da dies einen \texttt{finally}-Block ermöglicht, in der sämtliche Verbindungen zur Datenbank definitiv geschlossen werden können. Dieses Kappen der Verbindungen ist sehr wichtig, um die Datenbank nicht mit zu vielen offenen Verbindungen zu blockieren.

\subsubsection{Logic-Klassen}
In den \texttt{Logic}-Klassen werden wie vorher beschrieben die Ergebnisse der Datenbankanfragen weiterverarbeitet. Neben den bisher beschriebenen Aufbereitungen werden hier auch die anderen Funktionen des REST-Service aufgerufen. Die Details der anderen Module, wie Clustern und der Newsanfrage, finden sich in den entsprechenden Komponenten-Kapiteln. 

Eine Besonderheit, die hier im Vordergrund stehen soll, ist die Einbindung der Daten für das Sentiment-Modell. Diese Informationen sind notwendig, um die Darstellung der Einflussfaktoren für die Sentimentanalyse eines Tweets zu ermöglichen. Da die Analyse im Daemon stattfindet und die Parameter, die zu dem Ergebnis geführt haben, nicht in der Datenbank vorgehalten werden, muss eine Möglichkeit gefunden werden, die Informationen auf einem anderen Weg in den REST-Service zu laden.

Die erste lauffähige Methode beinhaltete, die Sentiment-Klassen des Daemons in den REST-Service zu laden und die Analyse erneut für die aktuell angefragten Tweets durchlaufen zu lassen. Dies beinhaltet wegen der Zustandslosigkeit in jedem Aufruf ein neues Trainieren der Modelle. Diese Art der Redundanz erschien uns allerdings nicht haltbar. Die Methode, die uns das wiederholte Trainieren der Modelle abnahm, beinhaltete, die trainierten Modelle auf der Festplatte zu speichern und nach Bedarf im REST-Service zu laden. Die Modelle werden im Daemon trainiert und auf der Festplatte aktualisiert, sobald sich neue, von uns gelabelte Tweets, in der Datenbank befinden. Wie im 
%TODO Daemon oder senti
 Daemon-Kapitel beschrieben, wird der Thread, der diese Aktualisierung durchführt, einmal am Tag gestartet.
 
Die vorher beschriebene Eigenschaft der Zustandslosigkeit des REST-Service sorgte allerdings für ein weiteres Problem. Da aufgrund dieser Eigenschaft keine Informationen von einer Anfrage an den Rest-Service zur nächsten übertragen werden konnten, bedeutete dies, dass die Modelle für jede Anfrage neu geladen werden mussten. Bei etwa 5-6 MiB pro Modell und Sprache, bedeutet dieses Laden einen deutlichen Flaschenhals bei parallel laufenden Anfragen. Eine kleine Änderung der Klassenvariable für diese Modelle auf \texttt{static} sorgte dafür, dass die Modelle nur bei der ersten Anfrage geladen werden und danach weiterhin vorgehalten werden. Da unser Anspruch, möglichst präzise Informationen zu der Sentimentanalyse zu präsentieren, allerdings dadurch nicht mehr voll erfüllt wurde, musste eine Möglichkeit gefunden werden, die Modelle aktuell zu halten.

Der erste naive Ansatz hierzu war es, die Modelle im Speicher mithilfe einer Hashsumme mit den Modellen auf der Festplatte zu vergleichen. Da eine solche Summe allerdings erst dann für die Modelle auf der Festplatte berechnet werden kann, wenn diese in den Speicher geladen wurden, wurde diese Idee sehr schnell verworfen. Stattdessen wurde entschieden in den Modellen selbst ihre Erstellungszeit zu speichern. Diese Information ist sehr leicht auszulesen und konnte dann mit der Erstellungszeit der Dateien auf der Festplatte verglichen werden. Das Besondere bei dieser Methode ist, dass nicht die interne Erstellungszeit des Modells auf der Festplatte als Vergleichswert herangezogen wird, sondern der Zeitstempel im Dateisystem für die Datei. Sollte der Unterschied zwischen diesen beiden Zeitstempeln einen bestimmten Wert überschreiten, so ist das aktuelle Modell veraltet und wird neu geladen. Hierdurch konnte die zu ladende Menge an Daten pro Anfrage drastisch reduziert werden.

Da so ein akzeptabler Weg gefunden ist, die trainierten Modelle zwischen dem Daemon und dem REST-Service auszutauschen, können sowohl die Einflüsse für das Ergebnis der Sentimentanalyse, als auch die wichtigen Trainings-Tweets, die zu diesem Ergebnis geführt haben, ermittelt werden und an die nächste Schicht im REST-Service, die Serviceklassen, weitergeleitet werden.

\subsubsection{Service-Klassen}
\label{sec:serviceklassen}
Die \texttt{Service}-Klassen handeln, wie vorher beschrieben, die Kommunikation in Richtung Frontend ab. Neben dieser Kommunikation werden in diesen Klassen ebenfalls die Antworten erstellt, die dann endgültig an das Frontend geschickt werden. Der oben erwähnte \texttt{Envelope} wurde in einer früheren Version unseres Programms hier endgültig befüllt oder eventuelle Exceptions gefangen und in die entsprechenden Felder im \texttt{Envelope} geschrieben. Diese Informationen beinhalteten den Stacktrace und den Error-Code der gefangenen Exception. Ebenso wurden Informationen zu fehlenden oder fehlerhaften Anfrageparametern hier in einen Envelope geschrieben und an das Frontend weitergeleitet.  

Diese Herangehensweise an die Fehlerbehandlung hatte allerdings einen großen Nachteil. Der HTTP-Status-Code der Antwort des REST-Service war bei dieser Implementierung immer \texttt{200 OK}, egal ob ein Fehler im Programm vorlag, ein Parameter fehlerhaft war, oder die Anfrage ohne Probleme durchgelaufen war. Dies bedeutete, dass im Frontend zur Behandlung nicht vorhergesehener Fehler neben dem HTTP-Status der Antwort auch die internen Felder des \texttt{Envelope}s überprüft werden mussten. Um diese doppelte Überprüfung zu eliminieren wurde festgelegt, dass die HTTP-Status-Codes abgefangene Fehler im Programmcode widerspiegeln sollten. Hierzu wurden die Methoden der Klasse so umgeschrieben, dass sie nun explizit eine HTTP-Response zurückgaben. Die bisherigen \texttt{Envelope}s wurden dann als \texttt{entity} in diesen \texttt{Response}-Objekten gespeichert.

Diese Änderung ermöglichte es ebenfalls, \texttt{WebApplicationException}s für die Fehlerbehandlung zu benutzten. Eventuell geworfene Exceptions in einer tieferen Schicht des REST-Service werden nun hier gefangen und als \texttt{WebApplicationException} an das Frontend weitergereicht. Da diese \texttt{WebApplicationException} ebenfalls über ein HTTP-Response-Objekt an das Frontend weitergegeben wird, kann erneut der \texttt{Envelope} als \texttt{entity} gesetzt werden. Das bedeutet, dass der HTTP-Status-Code \texttt{500 Internal Server Error} einen Fehler anzeigt, aber die wichtigen Informationen über die Art des Fehlers dennoch am Frontend auslesbar sind. Diese Informationen waren in Entwicklungsprozess sehr hilfreich, da ein Fehler, der bei der Entwicklung des Frontends auftrat, mit sehr genauen Informationen an die Entwickler des REST-Service weitergeleitet werden konnte. 

Die Behandlung fehlerhafter Parameter wurde ebenfalls deutlich erleichtert. Das Protokoll der HTTP-Status-Codes beinhaltet einen speziellen Code, um anzuzeigen, dass die Anfrage an den Server fehlerhaft war: \texttt{400 Bad Request}. Dieser Code konnte nun verwendet werden, um anzuzeigen, dass notwendige Parameter fehlten oder Parameter einen ungültigen Wert hatten.

Ein weiteres Feature, das durch diese Änderung ermöglicht wurde, ist das Caching der Ergebnisse im Browser. Hierzu wurde eine zusätzliche Methode in die unteren beiden Schichten des REST-Service eingefügt, die überprüft, wann das letzte mal für einen bestimmten Suchbegrif neue Daten von Twitter abgefragt wurden. Fragt ein Browser zum ersten mal nach der aktuellen Ressource, wird diese Information zusätzlich im Header der HTTP-Response unter dem Feld \texttt{Last-modified} gespeichert. Diese Information wird bei einer erneuten Anfrage an die gleiche Ressource erneut im Header mitgeschickt und kann dann zu Beginn der Methode ausgelesen und mit dem erneut aus der Datenbank abgefragten Zeitstempel verglichen werden. Handelt es sich um den gleichen Zeitstempel, so genügt es eine HTTP-Response mit dem HTTP-Status-Code \texttt{304 Not\_Modified} an den Browser zurückzusenden. Dieser verwendet dann zur Anzeige die in der letzten Anfrage erhaltenen Daten. 

Diese Methode erspart die komplexen Datenbankanfragen, wenn sich der unterliegende Datensatz nicht geändert hat, und ersetzt sie durch eine einfache Anfrage, die über einen Primärschlüssel abgehandelt werden kann.