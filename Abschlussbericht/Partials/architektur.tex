Aus der zuvor beschriebenen Projektidee ergeben sich drei Aufgabenbereiche von TMetrics: die Beschaffung und Filterung der Daten von Twitter, ihre Analyse durch Verfahren innerhalb von TMetrics (beispielsweise das Clustering oder die Analyse des Meinungsbildes) und die abschließende Darstellung der Resultate für den Benutzer in einer Browser-Anwendung (im Folgenden auch als Frontend bezeichnet). Die daraus resultierende Grundstruktur ist in Abbildung \ref{arch1} sehen.

\begin{figure}[h]
\centering
\scalebox{0.7}{\input{Bilder/architecture1.tex}}
\caption{Grundstruktur}
\label{arch1}
\end{figure}

\section{Beschaffung der Daten}

Recherchen zu Projektbeginn haben gezeigt, dass die grundsätzliche Möglichkeit zum Zugriff auf Tweets, Benutzerinformationen und sonstige Daten über die Twitter-API besteht. Diese Möglichkeit ist allerdings auch mit einer Reihe von Einschränkungen verbunden. Diese ermöglichen nur den Zugriff auf Tweets der letzten Tage und begrenzen außerdem die Anzahl der Tweets, welche innerhalb eines spezifischen Zeitraums zurückgeliefert werden können. Das macht es notwendig, dass TMetrics die benötigten Daten in regelmäßigen Abständen von Twitter abruft und in einer eigenen Datenbank speichert. Dies geschieht durch einen kontinuierlich laufenden Prozess, welcher von uns als Daemon bezeichnet wird. Da die Gesamtheit aller auf Twitter verfügbaren Daten unsere verfügbaren Kapazitäten überschreiten würde, haben wir uns dafür entschieden, auf diese Weise nur jene Daten zu sammeln, welche mit bereits eingegebenen Suchbegriffen in Verbindung stehen. Für diese Suchbegriffe war allerdings der Anspruch, sämtliche verfügbaren Daten zu sammeln, selbst wenn dafür zunächst noch keine Darstellung im Frontend vorgesehen war. Aus diesem Grund orientiert sich das Datenbankschema an den von Twitter zur Verfügung stehenden Daten. Um diese Entscheidungen zu realisieren, war eine Auswahl von Technologien erforderlich. 

Bei der Wahl der Datenbank bestand Einigkeit über den Einsatz eines relationalen Datenbanksystems. Außerdem sollte ein System gewählt werden, mit dem alle Projektmitglieder Erfahrung hatten, da die Datenbank als zentraler Bestandteil der Projektarchitektur erkannt wurde, mit der viele Programmbestandteile interagieren müssen. Aus diesen Gründen fiel die Wahl auf MySQL, das sämtlichen Projektmitgliedern bekannt war. Des Weiteren gab es unter uns keinen Datenbankexperten, der eine besser geeignete Datenbank hätte vorschlagen können. Da das Datenbanksystem vor Projektbeginn nicht als wichtige Technologie erkannt wurde, bestand keine Zeit mehr für Recherchen zu Alternativen, da die dadurch entstandene Verzögerung wegen der zentralen Rolle der Datenbank den gesamten Projektfortschritt verzögert hätte. Da der Daemon in Java implementiert wurde und auf die Datenbank zugreifen sollte, war der Einsatz einer geeigneten Bibliothek als Schnittstelle notwendig. Aufgrund bestehender Erfahrungen fiel die Wahl dabei auf JDBC \cite{JDBC}.

Neben einer Schnittstelle zur Datenbank war ebenfalls eine Schnittstelle zu Twitter notwendig, um die zu speichernden Daten überhaupt erst zu erhalten. Die bereits erwähnte API funktioniert dabei nach dem REST-Prinzip (siehe Abschnitt \ref{resteinfuehrung}). Das bedeutet, dass der Zugriff auf bestimmte Arten von Daten mit einer bestimmten URL (Ressource) verbunden ist. So stellen beispielsweise die Tweets eine Ressource von Twitter dar, auf die dann mittels eines HTML-GET-Requests auf die entsprechende URL in Verbindung mit geeigneten Parametern (z.\,B. ein in dem Tweet vorkommender Suchbegriff oder Hashtag) zugegriffen werden kann. Die Antwort wird dann im JSON-Format zurückgeliefert. Allerdings ist diese API nicht öffentlich zugänglich, sondern erfordert einen Twitter-Account. Über diesen kann dann über das OAuth-Authentifizierungsprotokoll eine Reihe von Tokens erstellt werden, welche bei der REST-Anfrage übergeben werden müssen, um eine Antwort zu erhalten. Um diese Schwierigkeit zu umgehen, aber auch um die Kommunikation mit der REST-API allgemein sicherer und einfacher zu gestalten, wurde auch für diese Schnittstelle nach einer Java-Bibliothek gesucht. Dabei fiel die Wahl auf Twitter4J. In dieser Bibliothek ist es möglich, durch einmalige Angabe der benötigten Tokens eine Verbindung mit Twitter herzustellen. Über diese Verbindung können dann REST-Anfragen gestellt werden, wobei dedizierte Methoden die sichere Übergabe der benötigten Parameter ermöglichen. Sämtliche Anfragen sind dann damit automatisch authentifiziert. Zu Beginn wurde zu Testzwecken zunächst ein Twitter-Account angelegt. Im Verlauf des Projekts waren allerdings aufgrund von Beschränkungen des Zugriffsvolumens weitere Accounts notwendig. Ein genauerer Überblick über diese Beschränkungen allgemein sowie die daraus resultierende Funktionsweise des Daemon wird im weiteren Verlauf dieser Arbeit im Abschnitt der Daemon-Komponente (siehe Abschnitt \ref{sec:daemon}) geliefert.

\section{Darstellung der Daten}
\label{sec:architekturDarstellung}

Wie bereits erwähnt, sollen die gesammelten Daten auf Anfrage des Benutzers im Frontend (unter Umständen nach Abschluss zusätzlicher Analysen) dargestellt werden. Das Design des Frontends wird ausführlich im Abschnitt der entsprechenden Komponente beschrieben (siehe Kapitel \ref{sec:frontend}). Die grundsätzliche Idee war jedoch, sich an der Gestalt von Suchmaschinen zu orientieren. Das Element der zusätzlichen Analyse und Aufbereitung der vorhandenen Daten legt außerdem einen Vergleich zu Seiten wie Wolfram Alpha nahe. Das bedeutet, dass der Benutzer zu Beginn einen Suchbegriff eingibt, der in den zu untersuchenden Tweets vorkommen soll. Damit der Daemon nach bereits angefragten Begriffen suchen kann, werden diese in der Datenbank in eine Tabelle eingetragen. Hat der Daemon zu dem Begriff bereits Daten gesammelt, können diese zur Darstellung zurückgeliefert werden. Dabei gibt es eine Reihe unterschiedlicher Gesichtspunkte, nach denen die vorhandenen Daten dargestellt werden können, beispielsweise das aktuelle Meinungsbild, die Aktivität zu dem Suchbegriff im zeitlichen Verlauf oder das Clustering. Die Ergebnisse zu jedem dieser Gesichtpunkte werden in einer entsprechenden Box, der sogenannten Ansicht, dargestellt. Dabei benötigt jede Ansicht eine entsprechende Auswahl der Daten aus der Datenbank sowie unter Umständen die Ergebnisse von deren Analyse. Damit ist klar, dass eine Schnittstelle notwendig ist, welche es ermöglicht, von Client-Seite Informationen in die Server-Datenbank einzutragen (vor allem zum Hinzufügen neuer Suchbegriffe) und außerdem gemäß bestimmten Anfragen Daten aus der Server-Datenbank an den Client zu senden. Die Entscheidung fiel daher darauf, aufgrund von bereits bestehenden Erfahrungen von Projektmitgliedern sowie in Anlehnung an die bekannte Twitter-API einen REST-Service zu erstellen. Dieser wurde wie im Abschnitt der REST-Komponente (siehe Kapitel \ref{sec:rest}) näher beschrieben mithilfe der JAX-RS-Bibliothek Jersey als Tomcat-Servlet implementiert. Diese ermöglicht es, Ressourcen mit Java-Methoden zu verknüpfen, welche bei Aufruf der mit der Ressource verbundenen URL ausgeführt werden. Dabei wurde jede Ansicht mit einer Ressource verknüpft, welche die für die Ansicht benötigten Daten durch Aufruf einer GET-Anfrage zurückliefert. Die damit verknüpfte Methode beinhaltet dabei immer einen Zugriff auf die Datenbank über JDBC mittels einer geeigneten SQL-Anfrage. Informationen, welche die Anfrage einschränken, werden dabei als Parameter an die Anfrage angehängt und entsprechend in den SQL-Befehl eingefügt. Das Einfügen von Daten in die Datenbank geschieht analog über POST-Anfragen. Bei manchen Anfragen ist außerdem noch eine zusätzliche Analyse oder Aufbereitung der Daten notwendig, was im folgenden Abschnitt beschrieben wird. Diese finden nach Zugriff auf die Datenbank, jedoch vor Senden der Antwort an den Client durch das Jersey-Servlet statt. Als Format für die Antwort des REST-Services haben wir JSON gewählt, da es einen einfachen Zugriff durch JavaScript ermöglicht.

Die Notwendigkeiten zur Beschaffung und Darstellung der Daten liefert ein grundlegendes Architekturmodell von TMetrics bestehend aus Daemon und REST-Service, welches in Abbildung \ref{arch2} dargestellt ist.

\begin{figure}[h]
\centering
\scalebox{0.7}{\input{Bilder/architecture2.tex}}
\caption{Grundlegendes Architekturmodell}
\label{arch2}
\end{figure}

\section{Analyse der Daten}

Aus den beiden Hauptanwendungsbereichen Beschaffung der Daten von Twitter und Ausgabe der Daten an das Frontend ergibt sich die Projektstruktur von TMetrics: einerseits existiert ein REST-Service als Tomcat-Servlet auf dem Server, welcher auf Benutzeranfragen reagiert, und andererseits gibt es den Daemon, welcher kontinuierlich als gewöhnliche Java-Anwendung auf dem Server läuft. Dieser ursprünglichen Vorstellung nach bildet die MySQL-Datenbank die einzige Schnittstelle zwischen diesen beiden Bestandteilen. Damit waren zu Projektbeginn zwei grundsätzlich unabhängige Programme vorgesehen, welche an unterschiedlichen Stellen des Servers ausgeführt werden sollten. Aus diesem Grund wurden zwei separate Java-Projekte erstellt, welche im Folgenden Daemon und REST-Service genannt werden. Allerdings übersteigt der ursprüngliche Funktionsumfang von TMetrics die bisher vorgestellten Aufgabenbereiche dieser Bestandteile, welche sich jeweils nur auf das Auslesen und Speichern der Daten von Twitter und der Ausgabe dieser Daten an das Frontend beschränken. Hinzu kommt nämlich noch die Zielsetzung, dass die gesammelten Daten außerdem auf verschiedene Weisen analysiert werden sollen. Dies wirft die Frage auf, in welchem der Bestandteile diese Analyse stattfinden soll. Eine Durchführung im Daemon bedeutet dabei, dass die Analyse bereits bei Erhalt sämtlicher Daten durchgeführt wird und ihre Ergebnisse in der Datenbank persistent gehalten werden müssen. Im Gegensatz dazu wird eine Analyse im REST-Service nur durchgeführt, wenn eine entsprechende Anfrage des Benutzers gestellt wird. Das Speichern der dabei bestimmten Ergebnisse in der Datenbank ist möglich, aber nicht zwingend notwendig. Dabei muss in Betracht gezogen werden, wie häufig die Ergebnisse benötigt werden und wie schnell sie durch vom Daemon neu hinzugefügte Daten veralten können. Da das Sentiment eines Tweets nur von seinem Text abhängt, ist die Sentiment-Analyse nicht von neu hinzukommenden Tweets abhängig, muss daher nicht aktualisiert werden und kann daher direkt beim Hinzufügen des Tweets durch den Daemon durchgeführt werden (es ist möglich, dass das Sentiment aktualisiert werden muss, falls sich das zu Grunde liegende Modell ändert, was jedoch vergleichsweise selten vorkommt. Details dazu im Abschnitt der Sentiment-Analyse, Kapitel \ref{sec:Sentiment}). Des Weiteren sind zur Erstellung des aktuellen Meinungsbildes eines Suchbegriffs ohnehin die Sentiment-Werte sämtlicher Tweets mit diesem Suchbegriff notwendig. Die Cluster-Analyse sowie die Bestimmung von Peaks und zugehörigen News in der Aktivitätskurve sind hingegen von sämtlichen Tweets in der Datenbank abhängig. Daher müssten die Ergebnisse dieser Verfahren ständig aktualisiert werden, sobald neue Tweets eines Suchbegriffs der Datenbank hinzugefügt werden. Da dies weitaus häufiger vorkommt als eine Anfrage an den Begriff, finden diese beiden Analysemethoden im REST-Service statt. Die Ergebnisse werden auf der Serverseite nach ihrem Abschicken an den Client nicht weiter gespeichert.

Einen Sonderfall bildet hierbei die Sentiment-Analyse. Nachdem im Projektverlauf mehr Gewicht auf den Aspekt des explorativen Arbeitens auf den zurückgelieferten Daten gelegt wurde, ist es nun auch wünschenswert, dass im Frontend angezeigt werden kann, welche Einflussfaktoren das Sentiment eines Tweets bestimmen und aus welchen Trainingsdaten diese Einflussfaktoren hervorgehen. Diese zusätzlichen Informationen gehen aus dem Sentiment-Modell hervor, welches wie zuvor beschrieben Teil des Daemon-Projekts ist. Zur Anzeige im Frontend müssen sie nun allerdings auch im REST-Service verfügbar sein. Eine Erweiterung der Datenbank um diese Einflussfaktoren wurde aufgrund des erhöhten Speicherbedarfs sowie der notwendigen Änderungen an der Datenbank mit Hinblick auf den Projektstand nicht vorgenommen. Stattdessen wurde entschieden, dass für Tweets, für die die Einflussfaktoren abgerufen werden, das Sentiment noch einmal erneut im REST-Service bestimmt wird. Der dadurch entstehende Zusatzaufwand ist hinnehmbar, da davon auszugehen ist, dass dies nur für einen Bruchteil der Tweets in der Datenbank durchgeführt wird. Damit ist allerdings der Einsatz der Klassen des Sentiment-Modells im REST-Service notwendig, sodass keine strikte Trennung beider Projekte mehr gegeben ist. Die Integration der Analysemethoden in das Architekturmodell ist in Abbildung \ref{arch3} zu sehen.

\begin{figure}[h]
\centering
\scalebox{0.7}{\input{Bilder/architecture3.tex}}
\caption{Architekturmodell mit Analysemethoden}
\label{arch3}
\end{figure}