\section{Server}
\subsection{Anforderungen und Grundsteine}
Nachdem die ersten allgemeinen Anforderungen an das Projekt durch das Projektteam festgelegt wurden, ergaben sich daraus ebenfalls die ersten konkreten Anforderungen an den nötigen technischen Unterbau. Da jedoch noch nicht alle Anforderungen bis ins Detail ausgearbeitet waren, wurden einige Punkte umgesetzt, die sich letztendlich nicht als zwingend notwendig erwiesen haben. Im folgenden Abschnitt werden die Details der Services auf dem Server und die generelle technische Umgebung beschrieben.

Aufgrund des allgemeinen Wunsches, laufende Services so weit wie möglich frei konfigurieren zu können, um z.\,B. Datenbank, HTTP, Mail und weitere Server flexibel an evtl. wechselnde Anforderungen anpassen zu können, war schnell klar, dass ein voller root-Zugang definitiv von Vorteil, wenn nicht unabdingbar wäre. Ein freier root-Zugang versprach ebenfalls schnelle Reaktionen und somit die Vermeidung von unnötigen Wartezeiten und Nachfragen bei der IVV (Informations-Verarbeitungs-Versorgungseinheit des Fachbereiches).

Erste Erkundigungen bei der IVV ergaben jedoch schnell, dass die Möglichkeiten hier stark eingeschränkt sein würden, sodass die Alternative, einen unabhängigen Server durch einen externen Anbieter zu mieten, auf der Hand lag. Die Wahl fiel auf den kleinsten vServer des Anbieters Server4You. Da die Leistungswerte bezüglich RAM und CPU des virtuellen Servers mindestens denen eines durch die IVV zur Verfügung gestellten Rechners entsprachen, war damit der erste technische Grundstein des Servers festgelegt.
Der zweite Grundstein bestand aus der Wahl des Betriebssystems. Zur Verfügung standen CentOS 6, Debian 6 und Ubuntu 10.04 LTS, jeweils in einer minimalen Variante und einer mit einem Hosting-Tool ausgestatteten.
Obwohl sowohl CentOS 6 als auch Debian 6 neueren Datums sind als Ubuntu 10.04 LTS, machten im Team vorherrschende Kenntnisse über Ubuntu diese Wahl ebenfalls relativ einfach. Da keinerlei Erfahrung mit dem gegebenem Hosting-Tool (Plesk) im Team vorhanden war und wir hier nicht künstlich in den Möglichkeiten eingeschränkt werden wollten, fiel die Wahl auf Ubuntu 10.04 LTS in der minimalen Variante.

Ein erster Überblick über die gegebenen Anforderungen schien nicht gegen Ubuntu 10.04 LTS zu sprechen, da für alle relevanten Systemdienste wie z.\,B. Tomcat, Apache und MySQL in genügend aktuellen Versionen vorzuliegen schienen.
Im Ergebnis kann aber festgehalten werden, dass Ubuntu für unser Team definitiv die richtige Wahl war, da hier keinerlei weitere Einarbeitungszeiten nötig wurden und alle Teammitglieder selbständig und ohne Probleme mit dem System arbeiten konnten.

Da zu diesem Zeitpunkt noch nicht endgültig feststand, wie der Funktionsumfang unseres Projektes exakt aussehen wird, standen noch einige Punkte wie eine Benutzerverwaltung oder Zugänge im Raum, welche im weiteren Verlauf jedoch an Bedeutung verloren. Dies war zunächst jedoch ein weiteres Argument für einen unabhängigen Server, denn nur so war es möglich, ohne große Aufwände ein eigenes und kostenloses Zertifikat zu integrieren um so die verschlüsselte Verbindung zwischen Browser und Server zu gewährleisten. Dies sollte sich im weiteren Verlauf dennoch als ein durchaus nützlicher Pluspunkt herausstellen.
Um evtl benötigte Mailadressen für eine Registrierung bei Twitter zur Verfügung zu haben, wurde die Idee begrüßt einen eigenen Mailserver zu betreiben.

\subsection{Projektname und Grundkonfiguration}
Nachdem die Basis des Servers nun also gegeben war, bestand der nächste Schritt darin, die einzelnen Services zu installieren, konfigurieren und unseren Anforderungen anzupassen.
Um den Server über einen Namen ansprechen zu können, legte sich das Team relativ schnell zunächst auf \texttt{twittermetrics} und später dann auf \texttt{tmetrics.de} fest. Der Grund für diesen Wechsel war, dass wir über den Anbieter StartSSL.com kein Zertifikat erhalten konnten, welches einen Markennamen wie z.\,B. Twitter im Domainnamen enthält. Daher wurde im allgemeinen Konsens der Name tmetrics gewählt. Dieser ließ den zusätzlichen Interpretationsspielraum, dass man das t sowohl für Twitter als auch für Trend stehen könne.

Damit war der Einstiegspunkt für die Konfiguration des Webservers gegeben. Nachdem im Rahmen der allgemeinen Projekt Anforderungen schnell klar wurde, dass Java als zentrale Programmiersprache zum Einsatz kommen sollte, wurde ein Server benötigt, welcher Java Programme nativ zur Beantwortung der Browser-Requests ausführen kann. Aufgrund vorhandener Erfahrung mit den Produkten der Apache Software Foundation lag die Wahl eines Tomcat als Application Server sehr nahe. Weitere Alternativen wie Jetty oder der sehr mächtige WebSphere von IBM wurden daher nicht weiter untersucht.
Obwohl der Tomcat durchaus in der Lage ist statischen Content wie z.\,B. HTML, CSS und JavaScript auszuliefern, wurde für diesen Teil auf einen klassischen Apache Webserver gebaut.
Nebst dem Grund, dass der Apache bei der Auslieferung statischen Contents im Allgemeinen etwas schneller ist als der Tomcat, war auch hier wieder der im Team vorherrschende Erfahrungsschatz ein ausschlaggebendes Kriterium. Hier standen sich nur grundsätzlich vorhandene Erfahrungen der Konfiguration eines Tomcat mit tiefer gehenden und langjährigen Erfahrungen im Umgang mit dem Apache gegenüber.

Die Konfiguration entsprechender vHosts für den Domainnamen und Subdomains, der entsprechenden Einstellung für eine bestmögliche Verschlüsselung und die Einrichtung einiger Umleitungen um lediglich den Zugriff mittels HTTPS zu gestatten, stellten daher keine größere Herausforderung dar.

Interessanter war jedoch die Verbindung des Tomcat mit dem Apache. Da der Tomcat als eigenständiger Server auf unabhängigen Ports läuft, wäre es möglich gewesen, relativ einfach mittels des Apache-Proxy-Moduls \texttt{mod\_proxy} die Anfragen, welche an einen bestimmten externen Pfad gerichtet sind, intern auf den HTTP-Port des Tomcat umzuschreiben. 
Das Modul \texttt{mod\_jk} ermöglicht jedoch die Kommunikation über das \texttt{Apache JServ Protocol} (AJP) und somit eine deutlich tiefer gehende Kommunikation zwischen Application- und Web-Server. Von einfachen Diagnosemöglichkeiten, wie einer Kontrolle durch anpingen ob der Applicationserver noch läuft, bishin zu Anforderungen an Loadbalancing bietet AJP somit deutliche Vorteile gegenüber dem naiven Ansatz mittels HTTP-Proxy und wurde daher hier eingesetzt.
Nachdem der Tomcat erfolgreich mit dem Apache verbunden werden konnte, wurden alle externen Zugriffsmöglichkeiten abgeschaltet, sodass der Tomcat nur noch via AJP über den Apache zu erreichen ist.

Um während des Entwicklungsprozesses stets eine nicht zwingend vollständig fehlerfreie Testumgebung, parallel aber auch immer eine funktionsfähige Produktivversion zur Verfügung zu haben, wurden hierzu die Subdomains \texttt{www.} und \texttt{dev.} eingerichtet. Hierzu wurde der REST Service unter zwei verschiedenen Pfaden auf den Tomcat deployed. Unterhalb der URL \url{www.tmetrics.de/rest} stand der REST Service somit nativ zur Verfügung. Hinter der URL \url{dev.tmetrics.de/rest} verbarg sich jedoch zunächst ein Reverse-Proxy, welcher die Anfragen an \url{www.tmetrics.de/rest_dev} umgeleitet hat. Der statische Content unterhalb dieser beiden Domains wurde einfach aus zwei verschiedenen Verzeichnissen geliefert.

Die nächste Anforderung bestand darin, die fertig kompilierten REST-Projekte auf den Tomcat zu deployen. Hierzu wird einfach auf die Tomcat eigene Manageroberfläche zurückgegriffen. Damit lässt sich eine .war Datei einfach hochladen und auf einen bestimmten Pfad deployen. Dies stellte im Gegensatz zum Einbinden via Dateisystem und anschließendem Reload des Tomcat die einfachere und damit bevorzugte Möglichkeit gar.

Normalerweise ist der Zugang zu der Management-Konsole lediglich über ein Passwort mittels des \textit{Basic Auth} Verfahrens gesichert, was ohne eine sichere Verbindung über HTTPS ein gewisses Sicherheitsrisiko geboten hätte, da das Passwort in jedem Request des Browsers mitgeschickt wird und somit ohne große Mühen von potentiellen Angreifern hätte ausgelesen werden können.
Da wir bereits eine gesicherte Verbindung einsetzen und die Management-Konsole wie alle anderen Tomcat-Applikationen über den Apache ausgeliefert werden, bestand an dieser Stelle kein weiterer Handlungsbedarf und die Konfiguration des Tomcat war somit abgeschlossen.

Von den vorhandenen Zertifikaten profitierte ebenfalls die Einrichtung der Mailserver. So konnten sowohl der SMTP-Server \texttt{postfix} als auch der IMAP- und POP-Server \texttt{dovecot} problemlos für verschlüsselte Verbindungen eingerichtet werden. Die Webmail-Anwendung \texttt{SquirrelMail} (\url{https://mail.tmetrics.de}) nutzt zur Beschleunigung der Zugriffe noch das \texttt{imapproxy} Paket. Somit konnte zur Registrierung der verschiedenen Twitter-Accounts, die für die Minions notwendig waren bequem über bekannte lokale Clients oder ein Webinterface gearbeitet werden.

Als letzter Service sei an dieser Stelle der MySQL-Server und dessen Konfiguration erwähnt. Das reine Installieren des MySQL-Servers ging wie auch bei dem Tomcat und Apache über einen Shell-Aufruf nicht hinaus, und auch die weitere Konfiguration des MySQL-Servers hielt sich zunächst in Grenzen.
Aus Sicherheitsgründen wurde der Zugang von außen komplett blockiert, sodass nur von localhost aus auf den MySQL-Server zugegriffen werden konnte.
Diese Einstellung wurde im Laufe des Seminars verworfen, da es zu Testzwecken nötig wurde auch von außen Zugriff auf den MySQL-Server zu erhalten.

Da bei der ursprünglichen Konfiguration des MySQL-Servers aber auf die Einrichtung einer Verschlüsselung verzichtet wurde, wurde eine minimale Sicherheit der Datenbank durch unterschiedliche Benutzer umgesetzt. Nicht alle Datenbankbenutzer haben also von außen Zugriff auf die Datenbanken und jene, welche externen Zugriff haben, können nicht alle Daten verändern.
Der Verzicht auf eine verschlüsselte Datenbank-Verbindung war von verschiedenen Gründen getrieben. Zum einen sollten unnötige Performance-Einbußen vermieden werden, zum anderen konnte so ein potentieller \textit{point of failure} der Verbindung von Java zur Datenbank konsequent vermieden werden. Zumal nach anfänglicher Planung im späteren Produktivbetrieb sowieso wieder nur lokale Zugriffe stattfinden würden, wurde weiterer Aufwand an dieser Stelle für unnötig erachtet.

%TODO: Technik des Deamons beschreiben? Aber wie, ist ja nur ne JVM, eigentlich nix besonderes... Ist evtl hinreichend über den Architekturteil abgedeckt. - kannst ja nochmal im Architekturteil lesen ob dir das passt (und wenn nicht vielleicht da eher umschreiben, war mir selber nicht so sicher). Ist ja nichts aufregendes was man hier noch groß erwähnen muss - Andreas: ich lass es erstmal noch als Reminder hier stehen, sollte aber eigentlich passen.

Die Grundkonfiguration des Servers war somit gegeben und der Programmierarbeit stand nichts mehr im Wege.


\subsection{Ubuntu-Update auf virtuellem System}
Während die meisten Serverkomponenten so mehr oder weniger in ihrer endgültigen Konfiguration vorlagen, ergab sich in Bezug auf den MySQL-Server in den ersten zwei Wochen des Projektes bereits größerer Änderungsbedarf.

Um keine der durch Twitter gelieferten Information zu verlieren war es notwendig, mindestens die Tweets in dem Zeichensatz \texttt{utf8mb4\_general\_ci} zu speichern. Diese 4 Byte lange UTF8-Multibyte-Variante wurde von der eingesetzten MySQL-Version jedoch leider nicht unterstützt.%TODO Quell-Link?
Da auf der gegebenen Ubuntuversion keine neuere MySQL-Version verfügbar war, wurde somit ein Upgrade der Ubuntuversion notwendig.
Die Erwartungen, dass das Update eines Ubuntu-Systems so reibungslos funktioniert, wie man es von seinem privaten Computer gewohnt ist, wurden jedoch schnell zerstreut.
Nebst einiger konfigurationsbedingter Fehlermeldungen ließen sich einige kernelbezogene Fehlermeldung nicht ausmerzen. Eine daraufhin an den Server4You-Support gerichtete Nachfrage ergab, dass die virtuellen Systeme einen gemeinsamen Kernel einsetzen und dass dieser \textit{shared kernel} eben nicht mit Ubuntu 12.04 LTS kompatibel sei. Man wolle unseren vServer aber auf einen anderen \textit{shared host} umziehen, sodass ein Upgrade rein prinzipiell möglich sein sollte.
Da sich vor allem im Bereich der Mailserver-Konfiguration die Strutkur der Konfigurationsdateien nahezu vollständig geändert hatte, lief der erste Versuch auch mit neuerem \textit{shared kernel} nicht fehlerfrei durch.
Die aus den Fehlversuchen gewonnen Erfahrungen trugen jedoch dazu bei, dass der zweite Versuch mit dem neuen Kernel von Erfolg gekrönt war, sodass nach einigem Anpassen diverser Konfigurationsdateien endlich die neue Ubuntuversion fehlerfrei lief und somit auch die neue MySQL-Version inklusive der benötigten Kollation angeboten werden konnte.

Das Update der Ubuntuversion brachte nebst neuen Versionen an nahezu allen Serverkomponenten ebenfalls neue Versionen von Apache und OpenSSL mit sich. Die neuere Version der OpenSSL Bibliothek bot damit die Möglichkeit TLS v1.2 einzusetzen, womit die Sicherheit der HTTPS-Verschlüsselung letztendlich über das durchschnittliche Niveau der deutschen Onlinebanking-Anbieter gebracht werden konnte.

Ein weiterer Vorteil durch die Verwendung einer neueren Apache-Version ergab sich im Zusammenhang mit der Verwendung des von Google zur Verfügung gestellten Apache-Moduls \texttt{mod\_spdy}. Dies setzt als Mindestanforderung an den Apache die nun zur Verfügung stehende Version voraus.

\subsection{Performance-Optimierungen\label{sec:performance_opt}}
Da sich im Rahmen der Frontend Entwicklung ein Problem mit der durchschnittlichen maximalen Anzahl paralleler Verbindungen, die ein Browser zu einem Webserver offen halten kann, ergab, wurde versucht dieses Problem serverseitig durch die Verwendung des \texttt{mod\_spdy} zu beheben.
Das SPDY-Apache-Modul verspricht durch den Aufbau lediglich einer echten TCP-Verbindung zwischen Browser und Server die Performance durch Reduzierung des mehrfachen TLS-Handshake zu steigern. Dieses Modul dient der Erweiterung des HTTP-Protokolls bzw. der Einführung des SPDY-Prokokolls. Das Modul wird wird von Google implementiert und zur Verfügung gestellt, wobei das SPDY-Protokoll mittlerweile von den meisten gängigen Browsern unterstützt wird. Desweiteren dient das SPDY-Protokoll bzw. einige hier eingesetzte Techniken als Vorlage für die aktuell in den entsprechenden Gremien zur Abstimmung befindliche HTTP 2.0 Protokollversion.
Beim Einsatz des HTTP-Protokolls in der üblichen Version 1.1 muss für jede Ressource eine eigene Anfrage an den Server gestellt werden und somit jedes mal eine neue verschlüsselte Verbindung ausgehandelt werden. Das SPDY-Protokoll bündelt diese Anfragen innerhalb einer einzigen gesicherten TCP-Verbindung. Zunächst schien dies die Lösung zu sein, mehrere "'logische"' und vor allem parallele Anfragen als gewohnt anbieten zu können. Diese Annahme stellte sich jedoch als Fehler heraus. Tests ergaben, dass auch mit \texttt{mod\_spdy} nicht mehr parallel logische Verbindungen möglich waren als zuvor.
Somit war für unser System an dieser Stelle lediglich in Bezug auf die Auslieferung des statischen Content ein Performance-Vorteil vorhanden. Wir haben uns dennoch dafür entschieden, weiterhin \texttt{mod\_spdy} zu verwenden. Browser die dieses Protokoll nicht unterstützen fallen transparent auf HTTP(S) 1.1 (bzw. 1.0) zurück. 

Aufgrund von Problemen mit der parallelen Verarbeitung von PHP-Skripten im Zusammenhang mit \texttt{mod\_spdy} lief das eingesetzte \texttt{phpMyAdmin} nicht mehr, sodass für das PHP-Parsing noch ein \texttt{fgci}-Modul eingesetzt wurde. Nach der Installation der relevanten Apache-Module \texttt{libapache2-mod-fcgid} und \texttt{php5-cgi} und dem setzen des \texttt{fgci}-Handlers für \texttt{.php}-Dateien war aber auch dieses Problem behoben.

Da gegen Ende des Seminars die Performance von Datenbankoperationen nach und nach abnahm, nutzten wir einen kostenlosen Probemonat eines leistungsstärkeren dedizierten Servers. Eine Verbesserung bei der Datenbank und beim Daemon konnte festgestellt werden. Leider beseitigte das dennoch nicht alle Performance-Probleme, sodass das Team an dieser Stelle feststellte, dass eine Überarbeitung des Datenbankschemas wohl viel versprechender wäre als eine reine Leistungssteigerung der Hardware.

Um während der Präsentation dennoch ein einigermaßen performantes System zur Verfügung zu haben, wurden sämtliche Anfragen an den REST-Service mittels des Apache-Proxy-Moduls zwischengespeichert. Hierzu wurde der Aufruf des Rest Services auf einen anderen Pfad umgelegt (\url{www.tmetrics.de/rest_prod}) und auf dem alten Pfad (\url{www.tmetrics.de/rest}) ein Reverse-Proxy eingesetzt.
Nach einigen Untersuchungen in Bezug auf die verschiedenen Caching-Möglichkeiten, stellte sich heraus, dass leider nicht alles wie gewünscht gecached werden kann, da in den Anfrage URLs Query-Parameter wie z.\,B. \texttt{id=1} verwendet werden. Daher musste am REST-Service eine kleine Änderung vorgenommen werden, sodass alle Antworten nun mit einem Expires-Header ausgesendet werden. Dies hat zur Folge, dass alle Antworten des REST-Service sowohl im Browser als auch auf dem Proxy für 90 Minuten zwischengespeichert werden.
Im Zusammenhang mit dem Proxy ergibt sich also die Situation, dass sobald ein Besucher sich einmal die Auswertung für z.\,B. Merkel hat anzeigen lassen, diese direkt und unmittelbar auch für alle anderen Besucher zur Verfügung steht.
Somit konnte eine reibungslose Demonstration gewährleistet werden.
